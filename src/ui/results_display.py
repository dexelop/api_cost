"""
ê²°ê³¼ í‘œì‹œ UI ì»´í¬ë„ŒíŠ¸

í† í° ìˆ˜ì™€ ë¹„ìš© ì¶”ì • ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
"""

from typing import List
from datetime import datetime

import pandas as pd
import streamlit as st

from src.processors.base import ProcessedFile
from src.pricing.calculator import PriceCalculator
from src.tokenizers.file_tokenizer import FileTokenizer
from src.exporters.csv_exporter import CSVExporter
from src.exporters.excel_exporter import ExcelExporter
from src.exporters.json_exporter import JSONExporter


def render_results(
    processed_files: List[ProcessedFile],
    selected_models: List[str],
    output_ratio: float,
):
    """
    ê²°ê³¼ í‘œì‹œ UI ë Œë”ë§

    Args:
        processed_files: ì²˜ë¦¬ëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        selected_models: ì„ íƒëœ ëª¨ë¸ ID ë¦¬ìŠ¤íŠ¸
        output_ratio: ì¶œë ¥ í† í° ë¹„ìœ¨
    """
    if not processed_files:
        st.info("ğŸ“‚ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    if not selected_models:
        st.warning("âš ï¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    # í† í° ê³„ì‚°ê¸° ë° ê°€ê²© ê³„ì‚°ê¸° ì´ˆê¸°í™”
    tokenizer = FileTokenizer()
    calculator = PriceCalculator()

    # ì „ì²´ í† í° ìˆ˜ ê³„ì‚°
    total_tokens = 0
    file_token_details = []

    for pfile in processed_files:
        # íŒŒì¼ë³„ í† í° ìˆ˜ ê³„ì‚°
        token_count = tokenizer.count_tokens_from_processed_file(pfile)
        total_tokens += token_count.token_count

        file_token_details.append(
            {
                "íŒŒì¼ëª…": pfile.metadata.get("file_name", "Unknown"),
                "íƒ€ì…": pfile.file_type,
                "í† í° ìˆ˜": f"{token_count.token_count:,}",
            }
        )

    # í† í° ì •ë³´ í‘œì‹œ
    st.subheader("ğŸ“Š í† í° ë¶„ì„")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ì…ë ¥ í† í°", f"{total_tokens:,}")
    with col2:
        estimated_output = int(total_tokens * output_ratio)
        st.metric("ì˜ˆìƒ ì¶œë ¥ í† í°", f"{estimated_output:,}")
    with col3:
        st.metric("ì´ í† í°", f"{total_tokens + estimated_output:,}")

    # íŒŒì¼ë³„ í† í° ìˆ˜ í‘œì‹œ
    if len(processed_files) > 1:
        with st.expander("ğŸ“‹ íŒŒì¼ë³„ í† í° ìˆ˜"):
            df_files = pd.DataFrame(file_token_details)
            st.dataframe(df_files, use_container_width=True)

    st.divider()

    # ëª¨ë¸ë³„ ë¹„ìš© ê³„ì‚°
    st.subheader("ğŸ’° ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ")

    # ë¹„ìš© ì¶”ì •
    estimated_output = int(total_tokens * output_ratio)
    estimates = calculator.compare_models(
        selected_models, input_tokens=total_tokens, output_tokens=estimated_output
    )

    if not estimates:
        st.error("âŒ ì„ íƒëœ ëª¨ë¸ì˜ ë¹„ìš©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
    result_data = []
    for est in estimates:
        result_data.append(
            {
                "ëª¨ë¸": est.model.model_name,
                "ì œê³µì—…ì²´": est.model.provider.upper(),
                "ì…ë ¥ ë¹„ìš©": f"${est.input_cost:.6f}",
                "ì¶œë ¥ ë¹„ìš©": f"${est.output_cost:.6f}",
                "ì´ ë¹„ìš©": f"${est.total_cost:.6f}",
                "Context ìœˆë„ìš°": f"{est.model.context_window:,}",
            }
        )

    df_results = pd.DataFrame(result_data)

    # ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ
    st.dataframe(
        df_results,
        use_container_width=True,
        hide_index=True,
    )

    # ê°€ì¥ ì €ë ´í•œ ëª¨ë¸ ê°•ì¡°
    cheapest = estimates[0]
    st.success(
        f"ğŸ’¡ **ê°€ì¥ ì €ë ´í•œ ëª¨ë¸**: {cheapest.model.model_name} "
        f"(${cheapest.total_cost:.6f})"
    )

    # ë‚´ë³´ë‚´ê¸°
    st.divider()
    st.subheader("ğŸ“¥ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")

    csv_exporter = CSVExporter()
    excel_exporter = ExcelExporter()
    json_exporter = JSONExporter()

    # CSV ë‹¤ìš´ë¡œë“œ (1í–‰)
    st.markdown("**CSV í˜•ì‹**")
    col1, col2, col3 = st.columns(3)

    with col1:
        # íŒŒì¼ë³„ í† í° ì •ë³´ CSV
        csv_files = csv_exporter.export_file_tokens(processed_files)
        st.download_button(
            label="ğŸ“„ íŒŒì¼ í† í° ì •ë³´",
            data=csv_files,
            file_name=f"file_tokens_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            help="íŒŒì¼ë³„ í† í° ìˆ˜ ì •ë³´ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        )

    with col2:
        # ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ CSV
        csv_costs = csv_exporter.export_cost_estimates(estimates, output_ratio)
        st.download_button(
            label="ğŸ’° ë¹„ìš© ë¹„êµ",
            data=csv_costs,
            file_name=f"cost_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            help="ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ ì •ë³´ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        )

    with col3:
        # í†µí•© CSV
        csv_combined = csv_exporter.export_combined(processed_files, estimates, output_ratio)
        st.download_button(
            label="ğŸ“Š ì „ì²´ ë¦¬í¬íŠ¸ (CSV)",
            data=csv_combined,
            file_name=f"full_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            help="ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•œ í†µí•© ë¦¬í¬íŠ¸ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        )

    # Excel & JSON ë‹¤ìš´ë¡œë“œ (2í–‰)
    st.markdown("**Excel & JSON í˜•ì‹**")
    col4, col5, col6 = st.columns(3)

    with col4:
        # Excel ì›Œí¬ë¶
        excel_data = excel_exporter.export_workbook(processed_files, estimates, output_ratio)
        st.download_button(
            label="ğŸ“Š Excel ì›Œí¬ë¶",
            data=excel_data,
            file_name=f"llm_cost_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="ìš”ì•½, íŒŒì¼ ì •ë³´, ë¹„ìš© ë¹„êµ ì‹œíŠ¸ë¥¼ í¬í•¨í•œ Excel ì›Œí¬ë¶",
        )

    with col5:
        # JSON ë°ì´í„°
        json_data = json_exporter.export_json(processed_files, estimates, output_ratio)
        st.download_button(
            label="ğŸ”§ JSON ë°ì´í„°",
            data=json_data,
            file_name=f"llm_cost_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            help="êµ¬ì¡°í™”ëœ JSON í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ë°ì´í„° ë‚´ë³´ë‚´ê¸°",
        )

    st.divider()

    # ì‹œê°í™”
    st.subheader("ğŸ“ˆ ë¹„ìš© ì‹œê°í™”")

    # ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
    chart_data = pd.DataFrame(
        {
            "ëª¨ë¸": [est.model.model_name for est in estimates],
            "ì´ ë¹„ìš© (USD)": [est.total_cost for est in estimates],
            "ì…ë ¥ ë¹„ìš© (USD)": [est.input_cost for est in estimates],
            "ì¶œë ¥ ë¹„ìš© (USD)": [est.output_cost for est in estimates],
        }
    )

    # ì´ ë¹„ìš© ë§‰ëŒ€ ê·¸ë˜í”„
    st.bar_chart(chart_data.set_index("ëª¨ë¸")["ì´ ë¹„ìš© (USD)"])

    # ì…ë ¥/ì¶œë ¥ ë¹„ìš© ë¶„í•´
    with st.expander("ğŸ“Š ì…ë ¥/ì¶œë ¥ ë¹„ìš© ë¶„í•´"):
        col1, col2 = st.columns(2)

        with col1:
            st.write("**ì…ë ¥ ë¹„ìš©**")
            st.bar_chart(chart_data.set_index("ëª¨ë¸")["ì…ë ¥ ë¹„ìš© (USD)"])

        with col2:
            st.write("**ì¶œë ¥ ë¹„ìš©**")
            st.bar_chart(chart_data.set_index("ëª¨ë¸")["ì¶œë ¥ ë¹„ìš© (USD)"])

    # ìƒì„¸ ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
        for est in estimates:
            st.markdown(f"### {est.model.model_name}")
            st.write(f"**ì œê³µì—…ì²´**: {est.model.provider}")
            st.write(f"**ì…ë ¥ í† í°**: {est.input_tokens:,}")
            st.write(f"**ì¶œë ¥ í† í°**: {est.output_tokens:,}")
            st.write(f"**ì…ë ¥ ê°€ê²©**: ${est.model.input_price:.4f} per 1K tokens")
            st.write(f"**ì¶œë ¥ ê°€ê²©**: ${est.model.output_price:.4f} per 1K tokens")
            st.write(f"**ì…ë ¥ ë¹„ìš©**: ${est.input_cost:.6f}")
            st.write(f"**ì¶œë ¥ ë¹„ìš©**: ${est.output_cost:.6f}")
            st.write(f"**ì´ ë¹„ìš©**: ${est.total_cost:.6f}")

            # ì¶”ê°€ ê¸°ëŠ¥
            features = []
            if est.model.vision_capable:
                features.append("ğŸ‘ï¸ Vision ì§€ì›")
            if est.model.online_search:
                features.append("ğŸŒ ì˜¨ë¼ì¸ ê²€ìƒ‰ ì§€ì›")
            if est.model.input_price_long:
                features.append("ğŸ“„ ì¥ë¬¸ ê°€ê²© ì§€ì›")

            if features:
                st.write("**ê¸°ëŠ¥**: " + ", ".join(features))

            st.divider()
